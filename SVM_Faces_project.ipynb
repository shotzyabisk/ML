{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shotzyabisk/ML/blob/main/SVM_Faces_project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ay2yqLSN-WXK"
      },
      "source": [
        "<img src=\"../src/packt-banner.png\" alt=\"\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qqOZ34E2-WXM"
      },
      "source": [
        "### Exercise 3: Build a SVM modle for Face Recognition Problem\n",
        "##### (24 points) --> your total will divided by 4 to get 6 points for this exercise.\n",
        "---\n",
        "\n",
        "We will use a very famous dataset, called Labelled Faces in the Wild, which\n",
        "consists of 1288 faces of famous people, and it is available at http://viswww.cs.umass.edu/lfw/lfw-funneled.tgz.\n",
        "\n",
        "However, note that it can be easily imported via scikit-learn from the datasets class.\n",
        "Each image consists of 1850 features: we could proceed by simply using each of them in the model.\n",
        "\n",
        "\n",
        "\n",
        "Fitting a SVM to non-linear data using the Kernel Trick produces non- linear decision boundaries.\n",
        "In particular, we seek to:\n",
        "* Build SVM model with radial basis function (RBF) kernel\n",
        "* Use a grid search cross-validation to explore ran- dom combinations of parameters."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4O1Bl4tA-WXN"
      },
      "source": [
        "### Step to do:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mI1YClX1-WXN"
      },
      "source": [
        "1. Loading the dataf from sklearn.datasets:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YCukQOoD-WXO"
      },
      "outputs": [],
      "source": [
        "from sklearn.datasets import fetch_lfw_people\n",
        "faces = fetch_lfw_people(min_faces_per_person=60)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cqB68Xf3-WXO"
      },
      "source": [
        "2. Since the data can be accessed from the sklearn.datasets module, you need to explore the dataset.\n",
        "    - (refer to the first 6 steps in Lab_1 could help you)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lwqVEabY-WXP"
      },
      "source": [
        "a- Print the field names (that is, the keys to the dictionary) (1 point)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ra3c6Pw6-WXP",
        "outputId": "adff6d5b-d773-4b29-90ef-21cb36549eb0"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "dict_keys(['data', 'images', 'target', 'target_names', 'DESCR'])"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# What fields are in the dictionary?\n",
        "faces.keys()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t5UQOljP-WXQ"
      },
      "source": [
        "b- Print the dataset description contained (1 point)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R6mgvHcv-WXQ"
      },
      "outputs": [],
      "source": [
        "print(faces['DESCR'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T8pphzX_-WXR"
      },
      "source": [
        "3. Print the data, its shape, and the target names. ( 3 points)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ltHNThrt-WXR",
        "outputId": "c19fd7ee-7945-4d69-a2ae-89d3b924d2fd"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[0.00130719, 0.01045752, 0.04836601, ..., 0.06405229, 0.0627451 ,\n",
              "        0.05620915],\n",
              "       [0.33333334, 0.3529412 , 0.39738563, ..., 0.07450981, 0.07189543,\n",
              "        0.00915033],\n",
              "       [0.19346406, 0.17254902, 0.14640523, ..., 0.06405229, 0.04836601,\n",
              "        0.04705882],\n",
              "       ...,\n",
              "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
              "        0.        ],\n",
              "       [0.00130719, 0.        , 0.        , ..., 0.12156863, 0.1267974 ,\n",
              "        0.12287582],\n",
              "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
              "        0.        ]], dtype=float32)"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# What does the data look like?\n",
        "faces['data']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6IIFPsX4-WXR",
        "outputId": "f322ff05-92e0-454d-9a76-b340e3b02d8b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(1348, 2914)"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# what is the shape of the data?\n",
        "faces['data'].shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xXgCm74o-WXS",
        "outputId": "0c41c7d6-621d-4370-b61c-245748601b63"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array(['Ariel Sharon', 'Colin Powell', 'Donald Rumsfeld', 'George W Bush',\n",
              "       'Gerhard Schroeder', 'Hugo Chavez', 'Junichiro Koizumi',\n",
              "       'Tony Blair'], dtype='<U17')"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# What is the target names?\n",
        "faces['target_names']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HsTCrhTa-WXS"
      },
      "source": [
        "4. Divide the data into features (X) using the faces.data and target (y) using faces.target (2 points)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "imw2BVFm-WXT"
      },
      "outputs": [],
      "source": [
        "X= faces.data\n",
        "y = faces.target"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DfF_RN7c-WXT"
      },
      "source": [
        "5. Splitting the data into training and testing sets. (2 point)\n",
        "\n",
        "We train the model with 70% of the samples and test with the remaining 30%."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OFT6tqwC-WXU",
        "outputId": "72026a50-683a-43d6-e108-8a651b4730ba"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(943, 2914)\n",
            "(405, 2914)\n",
            "(943,)\n",
            "(405,)\n"
          ]
        }
      ],
      "source": [
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state=42)\n",
        "\n",
        "# print the sizes of our training and test set to verify if the splitting has occurred properly.\n",
        "print(X_train.shape)\n",
        "print(X_test.shape)\n",
        "print(y_train.shape)\n",
        "print(y_test.shape)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PeHMLrDy-WXU"
      },
      "source": [
        "6. Declare SVM model with kernel='rbf', class_weight='balanced' (2 points)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z6JwK-IZ-WXU"
      },
      "outputs": [],
      "source": [
        "from sklearn.svm import SVC\n",
        "\n",
        "# write your code here\n",
        "\n",
        "svc_model = SVC(kernel='rbf', class_weight='balanced')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fBA94M6O-WXV"
      },
      "source": [
        "7. Use a grid search cross-validationwith 10 CV to explore random combinations of parameters. (3 points)\n",
        "    - we will adjust C, which controls the margin\n",
        "    - and Gamma (Î³), which controls the size of the radial basis function kernel, and determine the best model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qYb_pXUx-WXV",
        "outputId": "59d44676-fb85-4a89-807f-16509bec298a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'C': 50, 'gamma': 0.0005}\n",
            "0.7794064949608063\n"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "param_grid = {'C': [1,5,10,50],'gamma': [0.001,0.0005,0.01,0.1]}\n",
        "\n",
        "# write your code here for GridSearchCV:\n",
        "\n",
        "grid = GridSearchCV(svc_model, param_grid=param_grid, cv=10)\n",
        "grid.fit(X_train,y_train)\n",
        "print(grid.best_params_)\n",
        "print(grid.best_score_)"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "DZ3ku0O1-64k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LtuyP5tB-WXW"
      },
      "source": [
        "8. predict on the test set, using the best model from above step (best_estimator_) (5 points)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H5sYgELt-WXW"
      },
      "outputs": [],
      "source": [
        "# write your code here\n",
        "model = grid.best_estimator_\n",
        "yfit = model.predict(X_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BkEtOi-7-WXX"
      },
      "source": [
        "9. Model performances:\n",
        "Run the following code to print the model evaluation metric"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JHsJBqUa-WXX",
        "outputId": "4cf9ded2-a038-40a1-9c0e-f168db8471f4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   precision    recall  f1-score   support\n",
            "\n",
            "     Ariel Sharon       0.71      0.88      0.79        17\n",
            "     Colin Powell       0.84      0.82      0.83        84\n",
            "  Donald Rumsfeld       0.67      0.67      0.67        36\n",
            "    George W Bush       0.81      0.87      0.84       146\n",
            "Gerhard Schroeder       0.60      0.64      0.62        28\n",
            "      Hugo Chavez       0.88      0.52      0.65        27\n",
            "Junichiro Koizumi       0.80      0.75      0.77        16\n",
            "       Tony Blair       0.75      0.71      0.73        51\n",
            "\n",
            "         accuracy                           0.78       405\n",
            "        macro avg       0.76      0.73      0.74       405\n",
            "     weighted avg       0.78      0.78      0.78       405\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import classification_report\n",
        "labels = list(faces.target_names)\n",
        "print(classification_report(y_test,yfit,target_names=labels))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UmpHgVq6-WXX"
      },
      "source": [
        "10. What do you observe about the model performances? (5 points)\n",
        "\n",
        "The performances are pretty good, which shows the SVC is a good estimator for this kind of data.\n"
      ]
    }
  ],
  "metadata": {
    "anaconda-cloud": {},
    "interpreter": {
      "hash": "9be90a182e443121e767cfcadea61fa0eeced8ec62a9bd8ae9861f6c1d839655"
    },
    "kernelspec": {
      "display_name": "Python 3.9.5 ('venvml')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.5"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}